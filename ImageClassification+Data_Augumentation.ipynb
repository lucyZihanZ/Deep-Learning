{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9ljEMnv_prn",
        "outputId": "830d686e-b3ff-43cf-9929-daf126d75d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'course-deep-learning'...\n",
            "remote: Enumerating objects: 575, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 575 (delta 15), reused 19 (delta 8), pack-reused 547 (from 1)\u001b[K\n",
            "Receiving objects: 100% (575/575), 146.09 MiB | 24.61 MiB/s, done.\n",
            "Resolving deltas: 100% (303/303), done.\n",
            "Updating files: 100% (63/63), done.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.5.1+cu124)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.10.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: ipython>=7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (6.17.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.26.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.13.2)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->-r requirements.txt (line 3)) (4.13.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Collecting jedi>=0.16 (from ipython>=7.0->-r requirements.txt (line 8))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (6.4.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r requirements.txt (line 13)) (2.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.0->-r requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 9)) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 5)) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 13)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 13)) (2025.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.0->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 5)) (4.3.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.0->-r requirements.txt (line 8)) (0.2.13)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 5)) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->-r requirements.txt (line 3)) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 5)) (2.22)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# helper code from the course repository\n",
        "!git clone https://github.com/interactiveaudiolab/course-deep-learning.git\n",
        "# install common pacakges used for deep learning\n",
        "!cd course-deep-learning/ && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "# %cd course-deep-learning/"
      ],
      "metadata": {
        "id": "ai0112-4_veJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augumentation\n",
        "class LinearNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer_1 = nn.Linear(28*28, 1024)\n",
        "        self.layer_2 = nn.Linear(1024, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, heights, widths = x.size()\n",
        "\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.relu(self.layer_1(x))\n",
        "        x = self.layer_2(x)\n",
        "        return x\n",
        "\n",
        "class ConvNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(1,32,3,1) # (batch_size, channel, height, width)\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3,1)\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "      self.dropout1 = nn.Dropout(0.25)\n",
        "      self.dropout2 = nn.Dropout(0.5)\n",
        "      self.pool = nn.MaxPool2d(4) # because we use cnn is 2-dimensional\n",
        "      # use the fully-connected network to map our learned convolutional\n",
        "      # features to class predictions\n",
        "      self.fc1 = nn.Linear(64*6*6, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "      # inputs are expected to have shape (batch_size, 1, 28, 28)\n",
        "      x = self.conv1(x)\n",
        "      x = self.relu(x)\n",
        "\n",
        "      # output 2-d, first convolutional layer reshapes inputs to (batch_size, 32, 64, 64)\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.pool(x) # use pool method to reduce the spatial dimensions of the feature maps,\n",
        "# our pooling layer reduces inputs to (batch_size, 64, 6, 6)\n",
        "      x = self.dropout1(x)\n",
        "# we \"flatten\" inputs to (batch_size, 64*6*6) before passing a small fully-connected network\n",
        "# before: (batch_size, 64, 6, 6) now: (batch_size, 64*6*6)\n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.fc1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout2(x)\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      return x\n",
        "def param_count(m: nn.Module):\n",
        "      # assess the complexity\n",
        "      # count the number of trainable parameters (weights) in a model\n",
        "    return sum([p.shape.numel() for p in m.parameters() if p.requires_grad])\n",
        "\n",
        "model1 = LinearNetwork()\n",
        "model2 = ConvNetwork()\n",
        "\n",
        "params1 = param_count(model1)\n",
        "params2 = param_count(model2)\n",
        "\n",
        "print(f\"Parameters in fully-connected network: {params1}\")\n",
        "print(f\"Parameters in fully-connected network: {params2}\")\n",
        "print(f\"The convoluntional network has {params2/params1 :0.2f}x as many parameters\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1lv_7wA_yhz",
        "outputId": "57d5f3d4-e09c-4ef4-92da-a931a79c8fcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters in fully-connected network: 814090\n",
            "Parameters in fully-connected network: 315146\n",
            "The convoluntional network has 0.39x as many parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(save_path, epochs, batch_size, device=\"cpu\", use_conv=False):\n",
        "    \"\"\"\n",
        "    Train a neural network model for digit recognition on the MNIST dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    save_path (str):  path/filename for model checkpoint, e.g. 'my_model.pt'\n",
        "\n",
        "    epochs (int):     number of iterations through the whole dataset for training\n",
        "\n",
        "    batch_size (int): size of a single batch of inputs\n",
        "\n",
        "    device (str):     device on which tensors are placed; should be 'cpu' or 'cuda'.\n",
        "\n",
        "    use_conv (bool):  if True, use ConvNetwork; else, use LinearNetwork.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model (nn.Module): final trained model\n",
        "\n",
        "    save_path (str):   path/filename for model checkpoint, so that we can load our model\n",
        "                       later to test on unseen data\n",
        "\n",
        "    device (str):      the device on which we carried out training, so we can match it\n",
        "                       when we test the final model on unseen data later\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize model\n",
        "    if use_conv:\n",
        "      model = ConvNetwork()\n",
        "      print('Training convolutional neural network...')\n",
        "    else:\n",
        "      model = LinearNetwork()\n",
        "      print('Training fully-connected neural network...')\n",
        "\n",
        "    print(f'Parameters in model: {param_count(model)}')\n",
        "    model.to(device)\n",
        "\n",
        "    # initialize an optimizer to update our model's parameters during training\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    # optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "\n",
        "    # make a new directory in which to download the MNIST dataset\n",
        "    data_dir = \"./data/\"\n",
        "\n",
        "    # initialize a Transform object to prepare our data\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        lambda x: x>0,\n",
        "        lambda x: x.float(),\n",
        "    ])\n",
        "\n",
        "    # load MNIST \"test\" dataset from disk\n",
        "    mnist_test = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    # load MNIST \"train\" dataset from disk and set aside a portion for validation\n",
        "    mnist_train_full = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
        "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_train_full, [55000, 5000])\n",
        "\n",
        "    # initialize a DataLoader object for each dataset\n",
        "    train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size=1, shuffle=False)\n",
        "\n",
        "    # a PyTorch categorical cross-entropy loss object\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # time training process\n",
        "    st = time.time()\n",
        "\n",
        "    # keep track of best validation accuracy; if improved upon, save checkpoint\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # time to start training!\n",
        "    for epoch_idx, epoch in enumerate(range(epochs)):\n",
        "\n",
        "        # loop through the entire dataset once per epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        train_total = 0\n",
        "        model.train()\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # unpack data and labels\n",
        "            x, y = batch\n",
        "            x = x.to(device)  # we'll cover this in the next section!\n",
        "            y = y.to(device)  # we'll cover this in the next section!\n",
        "\n",
        "            # generate predictions and compute loss\n",
        "            output = model(x)  # (batch_size, 10)\n",
        "            loss = loss_fn(output, y)\n",
        "\n",
        "            # compute accuracy\n",
        "            preds = output.argmax(dim=1)\n",
        "            acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "            # compute gradients and update model parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update statistics\n",
        "            train_loss += (loss * len(x))\n",
        "            train_acc += (acc * len(x))\n",
        "            train_total += len(x)\n",
        "\n",
        "        train_loss /= train_total\n",
        "        train_acc /= train_total\n",
        "\n",
        "        # perform validation once per epoch\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        val_total = 0\n",
        "        model.eval()\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "\n",
        "            # don't compute gradients during validation\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # unpack data and labels\n",
        "                x, y = batch\n",
        "                x = x.to(device)  # we'll cover this in the next section!\n",
        "                y = y.to(device)  # we'll cover this in the next section!\n",
        "\n",
        "                # generate predictions and compute loss\n",
        "                output = model(x)\n",
        "                loss = loss_fn(output, y)\n",
        "\n",
        "                # compute accuracy\n",
        "                preds = output.argmax(dim=1)\n",
        "                acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "                # update statistics\n",
        "                val_loss += (loss * len(x))\n",
        "                val_acc += (acc * len(x))\n",
        "                val_total += len(x)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc /= val_total\n",
        "        print(f\"Epoch {epoch_idx + 1}: val loss {val_loss :0.3f}, val acc {val_acc :0.3f}, train loss {train_loss :0.3f}, train acc {train_acc :0.3f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            print(f\"New best accuracy {val_acc : 0.3f} (old {best_acc : 0.3f}); saving model weights to {save_path}\")\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"Total training time (s): {time.time() - st :0.3f}\")\n",
        "\n",
        "    return model, save_path, device\n"
      ],
      "metadata": {
        "id": "s4iwSyoCKTDh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation:\n",
        "There are many ways to squeeze some extra performance. One way is to use the data augmentation method:\n",
        "\n",
        "1) If dataset is small, we can use data augmentation method to augmentate it.\n",
        "\n",
        "2) Robust against real-world transformation. Invariant when validating on different models.\n"
      ],
      "metadata": {
        "id": "CIR1w8TNM9qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use Transform in torchvision to solve this problem\n",
        "data_dir = \"./data/\"\n",
        "\n",
        "# initialize a Transform object to prepare our data\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    lambda x: x>0,\n",
        "    lambda x: x.float(),\n",
        "])\n",
        "\n",
        "# load MNIST \"train\" dataset from disk\n",
        "mnist_train = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "# fetch an image from the MNIST dataset\n",
        "example_img, example_label = mnist_train[300]\n",
        "plt.imshow(example_img.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# perform a random affine transformation of an input (rotation, translation, shear)\n",
        "\n",
        "affine_aug = torchvision.transforms.RandomAffine(degrees=(-30, 30), translate=(0.25, 0.25), shear=(-45, 45))\n",
        "augmented = affine_aug(example_img)\n",
        "plt.imshow(augmented.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UYUxct7JNy2W",
        "outputId": "4aed9f58-357a-45b9-8b90-e97be10a04e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 34.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.92MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 12.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.05MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "euB5iM1yODio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}