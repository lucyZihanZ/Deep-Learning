{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vGc48p5iSYf",
        "outputId": "7a3c9665-cb62-458d-a8b1-4a5bde8184ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'course-deep-learning'...\n",
            "remote: Enumerating objects: 575, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 575 (delta 15), reused 19 (delta 8), pack-reused 547 (from 1)\u001b[K\n",
            "Receiving objects: 100% (575/575), 146.09 MiB | 8.71 MiB/s, done.\n",
            "Resolving deltas: 100% (303/303), done.\n",
            "Updating files: 100% (63/63), done.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.5.1+cu124)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.10.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: ipython>=7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (6.17.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.26.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.13.2)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->-r requirements.txt (line 3)) (4.13.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Collecting jedi>=0.16 (from ipython>=7.0->-r requirements.txt (line 8))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.0->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 9)) (6.4.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r requirements.txt (line 13)) (2.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.0->-r requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 9)) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 5)) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 13)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 13)) (2025.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.0->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 5)) (4.3.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.0->-r requirements.txt (line 8)) (0.2.13)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 5)) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->-r requirements.txt (line 3)) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->-r requirements.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 5)) (2.22)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/interactiveaudiolab/course-deep-learning.git\n",
        "# install common pacakges used for deep learning\n",
        "!cd course-deep-learning/ && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "# print(torch.__version__)\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cC8diH60igpC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/\" # address to store the data\n",
        "mnist_test = torchvision.datasets.MNIST(data_dir, train=False, download= True) # download the MNIST dataset\n",
        "mnist_train_full = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
        "# in PyTorch, use random_split()\n",
        "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train_full, [55000, 5000])\n",
        "type(mnist_train), type(mnist_val) # torch.utils.data.dataset.subset, iterable container, which we can fetch input-label pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVRKFvASkAmp",
        "outputId": "59bbdab8-6d45-4ad5-cc22-9018acf77dbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 132MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 33.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 71.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.52MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.utils.data.dataset.Subset, torch.utils.data.dataset.Subset)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = np.random.randint(0, len(mnist_test)) # get size using the len(),\n",
        "plt.imshow(mnist_test[d][0], cmap = 'gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "K3VsrMqUm6GZ",
        "outputId": "1bf5ce58-9c9e-4e7a-9cd0-37dde66f9d13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e47aa13b110>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stack multiple transformation using compose methods and personal function\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     lambda x: x >0 ,\n",
        "     lambda x: x.float()]\n",
        ")\n",
        "example_img, example_label = mnist_test[0]\n",
        "transformed = transform(example_img)\n",
        "print(example_label)\n",
        "print(transformed.shape)\n",
        "print(f\"Transformed image data:{(','.join(str(p.item()) for p in transformed.flatten()))[:100]}...\")\n",
        "# why can't use transformed[d][1] to display.\n",
        "# 1. MNIST can because it has PTL.Image object, which can display directly\n",
        "# 2. When doing transformation, the result will be tensor object. and the dimension will be [1,28,28],where 1 represents the gray level(灰度)\n",
        "# in order to transform into (28,28) and display in the PTL.Image, we need the squeeze() methods.\n",
        "plt.imshow(transformed.squeeze(), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "V88FnJ5UnePL",
        "outputId": "2be280da-15f3-45d0-de01-c9f30207d744"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "torch.Size([1, 28, 28])\n",
            "Transformed image data:0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e47cfe54950>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation for all train, val and test dataset\n",
        "mnist_test = torchvision.datasets.MNIST(data_dir, train = False, download = False, transform = transform)\n",
        "# load MNIST train dataset from the disk, because before we have finished download it to the disk\n",
        "mnist_train_full = datasets.MNIST(data_dir, train = True, download = False, transform=transform)\n",
        "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train_full, [55000,5000])\n",
        "example_img, example_label = mnist_test[0]"
      ],
      "metadata": {
        "id": "PdvJ1tRbv91g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want our training data is a random and shuffled dataset, so PyTorch provides a *DataLoader* class to handle the process starting from fetching data from a Dataset object, including shuffling, custom batch collation, and various random sampling schemes."
      ],
      "metadata": {
        "id": "gqOWSQderoyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 60\n",
        "# initialize the DataLoader for each dataset\n",
        "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle = True)\n",
        "val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "# grab the first batch from our DataLoader objects\n",
        "example_batch_img, example_batch_label = next(iter(train_dataloader))\n",
        "# 4 dimensional, 60: batch_size, refers to the number of training examples utilized in one iteration of the training process\n",
        "# one training iteration, there are 60 training examples\n",
        "# 1 color channels\n",
        "# 28*28 means the height and width.\n",
        "print(f\"Batch inputs shape:{example_batch_img.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlsHASVLrqdg",
        "outputId": "99a1ef01-5a07-4bb0-bb2d-4cad0cf6444a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch inputs shape:torch.Size([60, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Recognition\n",
        "# Training model\n",
        "class MNISTNetwork(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # MNIST image are (1, 28, 28) (channels, width, height)\n",
        "    self.layer_1 = torch.nn.Linear(28*28, 1024) # input: original pictures, width*height\n",
        "    # output: 1024 features,\n",
        "    self.layer_2 = torch.nn.Linear(1024, 10)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, channels, width, height = x.size()\n",
        "    x = x.view(batch_size, -1) # create an arrya of flattened images with dimension (batch_size, num_pixels)\n",
        "    x = self.relu(self.layer_1(x))\n",
        "    x = self.layer_2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model = MNISTNetwork()\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjrteQ9qsy8u",
        "outputId": "ee881904-0820-4ec0-9f59-a5e3dc08cbb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTNetwork(\n",
              "  (layer_1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (layer_2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classfication Loss\n",
        "# Usually we used the cross-entropy method.\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "preds = torch.randn(batch_size, 10) # random \"class score\" vectors, each with 10 scores corresponding to digits\n",
        "targets = torch.full((batch_size,), 7).long() # 'full' means using 7 to fill the (batch_size,1) dimension tensor\n",
        "# transformed it into tensor.int64 dimension.\n",
        "\n",
        "loss_fn(preds, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3GW4lghuCcL",
        "outputId": "c972f259-37e7-4fa1-dccb-e3b037a1290e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8077)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Picking an Optimizer: SGD\n",
        "weights = torch.zeros(10).requires_grad_(True)\n",
        "print(f\"Starting weights: {weights}, Sum: {weights.sum().item()}\")\n",
        "\n",
        "opt = torch.optim.SGD([weights], lr = 1.00)\n",
        "loss = 10 - weights.sum()\n",
        "loss.backward()\n",
        "\n",
        "opt.step()\n",
        "\n",
        "print(f\"Starting weights: {weights}, Sum: {weights.sum().item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyHV6n_Pwa3T",
        "outputId": "b0395f6a-6bd1-4430-9b9f-632979018245"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting weights: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True), Sum: 0.0\n",
            "Starting weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True), Sum: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The process of saving snapshots of a model during training is often called checkpointing,\n",
        "# and PyTorch offers utilities to make saving and loading models simple\n",
        "# In NN, it means saving weights(parameters),  the PyTorch models have a .state_dict() method\n",
        "model = MNISTNetwork()\n",
        "print(\"Names of network weights:\", list(model.state_dict().keys()))\n",
        "# save weights to the disk\n",
        "torch.save(model.state_dict(), \"dummy_weights.pt\")\n",
        "# load weights from the disk and overwrite network weights\n",
        "model.load_state_dict(torch.load(\"dummy_weights.pt\")) # useful when want to continue computing the result\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eglPedwVwrab",
        "outputId": "b79864cf-9f3a-406d-83b8-4fa9b24cd9c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Names of network weights: ['layer_1.weight', 'layer_1.bias', 'layer_2.weight', 'layer_2.bias']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a0bc561fee94>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"dummy_weights.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTNetwork(\n",
              "  (layer_1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (layer_2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put all together to construct a loop\n",
        "def training_loop(save_path, epochs, batch_size, device = 'cpu'):\n",
        "  # define several training utilities\n",
        "    model = MNISTNetwork()\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
        "    data_dir = './data/'\n",
        "\n",
        "    transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     lambda x: x >0,\n",
        "     lambda x: x.float()])\n",
        "\n",
        "  # Load trainingset:\n",
        "    mnist_test = torchvision.datasets.MNIST(data_dir, train = False, download = False, transform = transform)\n",
        "    mnist_train_full = datasets.MNIST(data_dir, train = True, download = False, transform=transform)\n",
        "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_train_full, [55000,5000])\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size = batch_size, shuffle = True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size = batch_size, shuffle = True)\n",
        "    test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size = 1, shuffle = False)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    st = time.time()\n",
        "\n",
        "    for epoch_idx, epoch in enumerate(range(epochs)):\n",
        "        best_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        train_total  = 0\n",
        "        model.train()\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "      # clear gradient, to avoid gradients pile up\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "      # unpack data and labels\n",
        "          x, y = batch\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "      # generate the output, and compute the loss\n",
        "          output = model(x)\n",
        "          loss = loss_fn(output, y)\n",
        "\n",
        "          preds = output.argmax(dim=1)\n",
        "          acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "          loss.backward() # compute the gradients\n",
        "          optimizer.step() # update the x\n",
        "\n",
        "      # update statistics\n",
        "          train_loss += (loss * len(x))\n",
        "          train_acc += (acc * len(x))\n",
        "          train_total += len(x)\n",
        "        train_loss /= train_total\n",
        "        train_acc /= train_total\n",
        "\n",
        "    # per epoch, perform the val\n",
        "        val_acc = 0.0\n",
        "        val_total = 0.0\n",
        "        val_loss = 0.0\n",
        "        model.eval()\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "    # don't compute the gradients during validation\n",
        "    # only concern about the model evaluation, so no need to update the weights\n",
        "            with torch.no_grad():\n",
        "              x, y = batch\n",
        "              x = x.to(device)\n",
        "              y = y.to(device)\n",
        "\n",
        "              output = model(x)\n",
        "\n",
        "              loss = loss_fn(output, y)\n",
        "              preds = output.argmax(dim=1)\n",
        "              acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "              val_loss += (loss * len(x))\n",
        "              val_acc += (acc * len(x))\n",
        "              val_total += len(x)\n",
        "        val_loss /= val_total\n",
        "        val_acc /= val_total\n",
        "        print(f\"epoch:{epoch_idx + 1}; val loss {val_loss: 0.3f}, val accuracy: {val_acc: 0.3f}; train loss {train_loss:0.3f}; train acc:{train_acc: 0.3f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "\n",
        "            best_acc = val_acc\n",
        "            print(f\"New best accuracy; saving model weights to {save_path}\")\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "        print(f\"Total training time (s): {time.time() - st :0.3f}\")\n",
        "\n",
        "    return model, save_path, device\n",
        "\n",
        "\n",
        "# run our training loop\n",
        "model, save_path, device = training_loop(\"mnist_basic.pt\", 10, 60, \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFtSb1QbyoD_",
        "outputId": "e1a36185-26d1-4a53-963e-6964f7cda9ce"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1; val loss  1.872, val accuracy:  0.709; train loss 2.092; train acc: 0.552\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 15.717\n",
            "epoch:2; val loss  1.411, val accuracy:  0.769; train loss 1.630; train acc: 0.756\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 31.268\n",
            "epoch:3; val loss  1.063, val accuracy:  0.797; train loss 1.210; train acc: 0.796\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 46.807\n",
            "epoch:4; val loss  0.855, val accuracy:  0.822; train loss 0.934; train acc: 0.821\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 63.773\n",
            "epoch:5; val loss  0.731, val accuracy:  0.836; train loss 0.771; train acc: 0.837\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 79.510\n",
            "epoch:6; val loss  0.651, val accuracy:  0.845; train loss 0.671; train acc: 0.848\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 95.257\n",
            "epoch:7; val loss  0.595, val accuracy:  0.858; train loss 0.604; train acc: 0.857\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 111.027\n",
            "epoch:8; val loss  0.555, val accuracy:  0.860; train loss 0.556; train acc: 0.864\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 128.349\n",
            "epoch:9; val loss  0.523, val accuracy:  0.865; train loss 0.521; train acc: 0.869\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 143.849\n",
            "epoch:10; val loss  0.499, val accuracy:  0.868; train loss 0.493; train acc: 0.873\n",
            "New best accuracy; saving model weights to mnist_basic.pt\n",
            "Total training time (s): 159.596\n"
          ]
        }
      ]
    }
  ]
}